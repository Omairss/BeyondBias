{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import newspaper\n",
    "from googlesearch import search\n",
    "import pdb\n",
    "import tldextract\n",
    "from newspaper import Article\n",
    "from datetime import timedelta\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import newspaper\n",
    "from googlesearch import search\n",
    "import pdb\n",
    "import argparse\n",
    "import tldextract\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_url_bias(url, corpus):\n",
    "    \n",
    "    try:\n",
    "        return corpus.loc[corpus['source_url_processed'].str.contains(tldextract.extract(url).domain)]['bias'].values[0]\n",
    "    except IndexError:\n",
    "        return 'center'\n",
    "    \n",
    "def get_url_fact(url, corpus):\n",
    "    try:\n",
    "        return corpus.loc[corpus['source_url_processed'].str.contains(tldextract.extract(url).domain)]['fact'].values[0]\n",
    "    except IndexError:\n",
    "        return 'MIXED'\n",
    "    \n",
    "def get_search_query(url):\n",
    "\n",
    "    article = newspaper.Article(url)\n",
    "\n",
    "    article.download()\n",
    "    article.parse()\n",
    "    article.nlp()\n",
    "\n",
    "    query             = article.title\n",
    "    \n",
    "    try:\n",
    "        date_before       = article.publish_date + timedelta(days=2)\n",
    "        date_after        = article.publish_date - timedelta(days=2)\n",
    "\n",
    "        query_time_before = str(date_before.year) +\\\n",
    "                            '-' + str(date_before.month) +\\\n",
    "                            '-' + str(date_before.day)\n",
    "\n",
    "        query_time_after = str(date_after.year) +\\\n",
    "                            '-' + str(date_after.month) +\\\n",
    "                            '-' + str(date_after.day)\n",
    "        \n",
    "        query = query + ' before:' + query_time_before + ' after:' + query_time_after\n",
    "    \n",
    "    except TypeError:\n",
    "        \n",
    "        print('Date for the article not available. Finding other articles across all times')\n",
    "    \n",
    "    \n",
    "        \n",
    "    return query\n",
    "    \n",
    "\n",
    "    \n",
    "def get_query_results(search_query):\n",
    "    \n",
    "    alt_article_lists = [i for i in search(search_query, num = 10)]\n",
    "    search_results_df = pd.DataFrame(columns = ['link', 'domain', 'title', 'content'])\n",
    "\n",
    "    search_results_df['link'] = alt_article_lists\n",
    "    search_results_df['domain'] = search_results_df['link'].apply(lambda x: tldextract.extract(x).domain\\\n",
    "                                                                             + '.' + tldextract.extract(x).suffix)\n",
    "    \n",
    "    return search_results_df\n",
    "\n",
    "\n",
    "def parse_params():\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='Source Reliability')\n",
    "    parser.add_argument('--url',             type=str, default='')\n",
    "    params = parser.parse_args()\n",
    "    return params\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    \n",
    "    user_params = parse_params()\n",
    "    url         = user_params.url\n",
    "    corpus      = pd.read_csv('data/corpus.csv')\n",
    "\n",
    "    url_bias      = get_url_bias(url, corpus)\n",
    "    url_fact      = get_url_fact(url, corpus)\n",
    "    \n",
    "    query         = get_search_query(url)\n",
    "    query_results_df = get_query_results(query)\n",
    "    query_results_df = query_results_df.fillna('')\n",
    "\n",
    "\n",
    "    search_results_df = pd.merge(corpus, query_results_df, left_on = 'source_url_processed', right_on = 'domain')\n",
    "    search_results_df = search_results_df[~search_results_df['bias'].str.replace('-', ' ').str.contains('right')]\n",
    "    \n",
    "    search_results_df.to_csv('results/' + query + '.csv')\n",
    "\n",
    "    return search_results_df.to_dict(orient = 'index')\n",
    "\n",
    "\n",
    "def get_alternative_links(url):\n",
    "\n",
    "    corpus_url   = 'https://raw.githubusercontent.com/Omairss/BeyondBias/master/data/corpus.csv'\n",
    "    s            = requests.get(corpus_url).content\n",
    "\n",
    "    corpus       = pd.read_csv(io.StringIO(s.decode('utf-8')))\n",
    "\n",
    "    url_bias      = get_url_bias(url, corpus)\n",
    "    url_fact      = get_url_fact(url, corpus)\n",
    "    \n",
    "    query         = get_search_query(url)\n",
    "    query_results_df = get_query_results(query)\n",
    "    query_results_df = query_results_df.fillna('')\n",
    "\n",
    "\n",
    "    search_results_df = pd.merge(corpus, query_results_df, left_on = 'source_url_processed', right_on = 'domain')\n",
    "    search_results_df = search_results_df[~search_results_df['bias'].str.replace('-', ' ').str.contains('right')]\n",
    "    \n",
    "\n",
    "    return search_results_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCosine(body_1, body_2, title_1, title_2):\n",
    "    \n",
    "    bodies = (body_1, body_2)\n",
    "    titles = (title_1, title_2)\n",
    "    \n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    \n",
    "    tfidf_matrix_bodies = tfidf_vectorizer.fit_transform(bodies)\n",
    "    tfidf_matrix_titles = tfidf_vectorizer.fit_transform(titles)\n",
    "    \n",
    "    cosine_similarity_bodies=(cosine_similarity(tfidf_matrix_bodies[0:1], tfidf_matrix_bodies[1]))[0][0]\n",
    "    cosine_similarity_titles=(cosine_similarity(tfidf_matrix_titles[0:1], tfidf_matrix_titles[1]))[0][0]\n",
    "    \n",
    "    return 0.5*(cosine_similarity_bodies+cosine_similarity_titles)\n",
    "\n",
    "\n",
    "def getSimilarity(url1, url2):\n",
    "    \n",
    "    #url1 = 'https://www.newyorker.com/books/page-turner/how-jane-vonnegut-made-kurt-vonnegut-a-writer'\n",
    "    #url2 = 'https://www.nytimes.com/2007/04/12/books/12vonnegut.html'\n",
    "    \n",
    "    article1 = Article(url1)\n",
    "    article2 = Article(url2)\n",
    "    \n",
    "    article1.download()\n",
    "    article2.download()\n",
    "    \n",
    "    article1.parse()\n",
    "    article2.parse()\n",
    "    \n",
    "    body1=article1.text\n",
    "    body2=article2.text\n",
    "    \n",
    "    title1=article1.title\n",
    "    title2=article2.title\n",
    "    \n",
    "    return getCosine(body1, body2, title1, title2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date for the article not available. Finding other articles across all times\n"
     ]
    }
   ],
   "source": [
    "search_results_df = get_alternative_links('https://www.breitbart.com/news/turkey-denies-blocking-retreat-of-kurdish-forces-in-syria-official/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10977297172269668"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getSimilarity('https://www.breitbart.com/news/turkey-denies-blocking-retreat-of-kurdish-forces-in-syria-official/',\n",
    "              'https://www.nytimes.com/2007/04/12/books/12vonnegut.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.breitbart.com/news/turkey-denies-blocking-retreat-of-kurdish-forces-in-syria-official/'\n",
    "search_results_df['cosine_similarity'] = search_results_df['link'].apply(lambda x: getSimilarity(x, url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_url</th>\n",
       "      <th>source_url_processed</th>\n",
       "      <th>URL</th>\n",
       "      <th>fact</th>\n",
       "      <th>bias</th>\n",
       "      <th>link</th>\n",
       "      <th>domain</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>cosine_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>https://www.japantimes.co.jp/</td>\n",
       "      <td>japantimes.co.jp</td>\n",
       "      <td>https://mediabiasfactcheck.com/japan-times/</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>center</td>\n",
       "      <td>https://www.japantimes.co.jp/news/2019/10/18/w...</td>\n",
       "      <td>japantimes.co.jp</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.216166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>http://www.aljazeera.com/</td>\n",
       "      <td>aljazeera.com</td>\n",
       "      <td>http://mediabiasfactcheck.com/al-jazeera/</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>left-center</td>\n",
       "      <td>https://www.aljazeera.com/news/2019/10/turkey-...</td>\n",
       "      <td>aljazeera.com</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.277109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>http://www.timesofisrael.com/</td>\n",
       "      <td>timesofisrael.com</td>\n",
       "      <td>http://mediabiasfactcheck.com/times-of-israel/</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>left-center</td>\n",
       "      <td>https://www.timesofisrael.com/turkey-starts-bo...</td>\n",
       "      <td>timesofisrael.com</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.202082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>https://www.bloomberg.com/</td>\n",
       "      <td>bloomberg.com</td>\n",
       "      <td>http://mediabiasfactcheck.com/bloomberg/</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>left-center</td>\n",
       "      <td>https://www.bloomberg.com/news/articles/2019-1...</td>\n",
       "      <td>bloomberg.com</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.016945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>http://www.news24.com/</td>\n",
       "      <td>news24.com</td>\n",
       "      <td>http://mediabiasfactcheck.com/news24-south-afr...</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>center</td>\n",
       "      <td>https://www.news24.com/World/News/trump-defend...</td>\n",
       "      <td>news24.com</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.233539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>http://www.pri.org/</td>\n",
       "      <td>pri.org</td>\n",
       "      <td>http://mediabiasfactcheck.com/public-radio-int...</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>left-center</td>\n",
       "      <td>https://www.pri.org/stories/2016-08-24/turkey-...</td>\n",
       "      <td>pri.org</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.214544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>http://www.cnn.com/</td>\n",
       "      <td>cnn.com</td>\n",
       "      <td>http://mediabiasfactcheck.com/cnn/</td>\n",
       "      <td>MIXED</td>\n",
       "      <td>left</td>\n",
       "      <td>https://www.cnn.com/2019/10/12/middleeast/turk...</td>\n",
       "      <td>cnn.com</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.160726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      source_url source_url_processed  \\\n",
       "1  https://www.japantimes.co.jp/     japantimes.co.jp   \n",
       "2      http://www.aljazeera.com/        aljazeera.com   \n",
       "3  http://www.timesofisrael.com/    timesofisrael.com   \n",
       "4     https://www.bloomberg.com/        bloomberg.com   \n",
       "5         http://www.news24.com/           news24.com   \n",
       "8            http://www.pri.org/              pri.org   \n",
       "9            http://www.cnn.com/              cnn.com   \n",
       "\n",
       "                                                 URL   fact         bias  \\\n",
       "1        https://mediabiasfactcheck.com/japan-times/   HIGH       center   \n",
       "2          http://mediabiasfactcheck.com/al-jazeera/   HIGH  left-center   \n",
       "3     http://mediabiasfactcheck.com/times-of-israel/   HIGH  left-center   \n",
       "4           http://mediabiasfactcheck.com/bloomberg/   HIGH  left-center   \n",
       "5  http://mediabiasfactcheck.com/news24-south-afr...   HIGH       center   \n",
       "8  http://mediabiasfactcheck.com/public-radio-int...   HIGH  left-center   \n",
       "9                 http://mediabiasfactcheck.com/cnn/  MIXED         left   \n",
       "\n",
       "                                                link             domain title  \\\n",
       "1  https://www.japantimes.co.jp/news/2019/10/18/w...   japantimes.co.jp         \n",
       "2  https://www.aljazeera.com/news/2019/10/turkey-...      aljazeera.com         \n",
       "3  https://www.timesofisrael.com/turkey-starts-bo...  timesofisrael.com         \n",
       "4  https://www.bloomberg.com/news/articles/2019-1...      bloomberg.com         \n",
       "5  https://www.news24.com/World/News/trump-defend...         news24.com         \n",
       "8  https://www.pri.org/stories/2016-08-24/turkey-...            pri.org         \n",
       "9  https://www.cnn.com/2019/10/12/middleeast/turk...            cnn.com         \n",
       "\n",
       "  content  cosine_similarity  \n",
       "1                   0.216166  \n",
       "2                   0.277109  \n",
       "3                   0.202082  \n",
       "4                   0.016945  \n",
       "5                   0.233539  \n",
       "8                   0.214544  \n",
       "9                   0.160726  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.japantimes.co.jp/news/2019/10/18/world/trump-trumpets-turkish-cease-fire-kurd-ex-allies-must-vacate-syria-border-area-allowing-ankara-solidify-gains/',\n",
       " 'https://www.aljazeera.com/news/2019/10/turkey-military-operation-syria-latest-updates-191017051518215.html',\n",
       " 'https://www.timesofisrael.com/turkey-starts-bombing-kurds-in-syria-as-us-pulls-out-report/',\n",
       " 'https://www.bloomberg.com/news/articles/2019-10-17/trump-s-haphazard-syria-deal-leaves-erdogan-with-long-sought-win',\n",
       " 'https://www.news24.com/World/News/trump-defends-syria-pullout-denies-giving-turkey-green-light-for-invasion-20191016',\n",
       " 'https://www.pri.org/stories/2016-08-24/turkey-fighting-isis-syria-and-blocking-us-backed-kurds',\n",
       " 'https://www.cnn.com/2019/10/12/middleeast/turkey-syria-offensive-intl/index.html']"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(search_results_df['link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results_df['score'] = search_results_df['cosine_similarity']/np.log(np.array(search_results_df.index) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.311862\n",
       "2    0.252235\n",
       "3    0.145772\n",
       "4    0.010529\n",
       "5    0.130340\n",
       "8    0.097643\n",
       "9    0.069802\n",
       "Name: score, dtype: float64"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results_df['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
