{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import newspaper\n",
    "from googlesearch import search\n",
    "import pdb\n",
    "import tldextract\n",
    "from datetime import timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import newspaper\n",
    "from googlesearch import search\n",
    "import pdb\n",
    "import argparse\n",
    "import tldextract\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_url_bias(url, corpus):\n",
    "    \n",
    "    try:\n",
    "        return corpus.loc[corpus['source_url_processed'].str.contains(tldextract.extract(url).domain)]['bias'].values[0]\n",
    "    except IndexError:\n",
    "        return 'center'\n",
    "    \n",
    "def get_url_fact(url, corpus):\n",
    "    try:\n",
    "        return corpus.loc[corpus['source_url_processed'].str.contains(tldextract.extract(url).domain)]['fact'].values[0]\n",
    "    except IndexError:\n",
    "        return 'MIXED'\n",
    "    \n",
    "def get_search_query(url):\n",
    "\n",
    "    article = newspaper.Article(url)\n",
    "\n",
    "    article.download()\n",
    "    article.parse()\n",
    "    article.nlp()\n",
    "\n",
    "    query             = article.title\n",
    "    date_before       = article.publish_date + timedelta(days=2)\n",
    "    date_after        = article.publish_date - timedelta(days=2)\n",
    "\n",
    "    query_time_before = str(date_before.year) +\\\n",
    "                        '-' + str(date_before.month) +\\\n",
    "                        '-' + str(date_before.day)\n",
    "            \n",
    "    query_time_after = str(date_after.year) +\\\n",
    "                        '-' + str(date_after.month) +\\\n",
    "                        '-' + str(date_after.day)\n",
    "            \n",
    "            \n",
    "    query = query + ' before:' + query_time_before + ' after:' + query_time_after\n",
    "        \n",
    "    return query\n",
    "    \n",
    "\n",
    "    \n",
    "def get_query_results(search_query):\n",
    "    \n",
    "    alt_article_lists = [i for i in search(search_query, num = 10)]\n",
    "    search_results_df = pd.DataFrame(columns = ['link', 'domain', 'title', 'content'])\n",
    "\n",
    "    search_results_df['link'] = alt_article_lists\n",
    "    search_results_df['domain'] = search_results_df['link'].apply(lambda x: tldextract.extract(x).domain\\\n",
    "                                                                             + '.' + tldextract.extract(x).suffix)\n",
    "    \n",
    "    return search_results_df\n",
    "\n",
    "\n",
    "def parse_params():\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='Source Reliability')\n",
    "    parser.add_argument('--url',             type=str, default='')\n",
    "    params = parser.parse_args()\n",
    "    return params\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    \n",
    "    user_params = parse_params()\n",
    "    url         = user_params.url\n",
    "    corpus      = pd.read_csv('data/corpus.csv')\n",
    "\n",
    "    url_bias      = get_url_bias(url, corpus)\n",
    "    url_fact      = get_url_fact(url, corpus)\n",
    "    \n",
    "    query         = get_search_query(url)\n",
    "    query_results_df = get_query_results(query)\n",
    "    query_results_df = query_results_df.fillna('')\n",
    "\n",
    "\n",
    "    search_results_df = pd.merge(corpus, query_results_df, left_on = 'source_url_processed', right_on = 'domain')\n",
    "    search_results_df = search_results_df[~search_results_df['bias'].str.replace('-', ' ').str.contains('right')]\n",
    "    \n",
    "    search_results_df.to_csv('results/search_results.csv')\n",
    "\n",
    "    return search_results_df.to_dict(orient = 'index')\n",
    "\n",
    "\n",
    "def get_alternative_links(url):\n",
    "\n",
    "    \n",
    "    corpus      = pd.read_csv('data/corpus.csv')\n",
    "\n",
    "    url_bias      = get_url_bias(url, corpus)\n",
    "    url_fact      = get_url_fact(url, corpus)\n",
    "    \n",
    "    query         = get_search_query(url)\n",
    "    \n",
    "    print ('The query is:' + (query))\n",
    "    \n",
    "    query_results_df = get_query_results(query)\n",
    "    query_results_df = query_results_df.fillna('')\n",
    "\n",
    "\n",
    "    search_results_df = pd.merge(corpus, query_results_df, left_on = 'source_url_processed', right_on = 'domain')\n",
    "    search_results_df = search_results_df[~search_results_df['bias'].str.replace('-', ' ').str.contains('right')]\n",
    "    \n",
    "\n",
    "    return search_results_df.to_dict(orient = 'index')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The query is:New Year, new laws: Obamacare, pot, guns and drones before:2014-1-1 after:2013-12-28\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: {'URL': 'https://mediabiasfactcheck.com/the-peoples-cube/',\n",
       "  'bias': 'center',\n",
       "  'content': '',\n",
       "  'domain': 'thepeoplescube.com',\n",
       "  'fact': 'LOW',\n",
       "  'link': 'https://thepeoplescube.com/peoples-blog/america-duck-yeah-victory-merchandise-t12741.html',\n",
       "  'source_url': 'http://thepeoplescube.com',\n",
       "  'source_url_processed': 'thepeoplescube.com',\n",
       "  'title': ''},\n",
       " 4: {'URL': 'http://mediabiasfactcheck.com/cnn/',\n",
       "  'bias': 'left',\n",
       "  'content': '',\n",
       "  'domain': 'cnn.com',\n",
       "  'fact': 'MIXED',\n",
       "  'link': 'http://www.cnn.com/sitemaps/sitemap-articles-2013-12.xml',\n",
       "  'source_url': 'http://www.cnn.com/',\n",
       "  'source_url_processed': 'cnn.com',\n",
       "  'title': ''},\n",
       " 5: {'URL': 'https://mediabiasfactcheck.com/ndtv/',\n",
       "  'bias': 'left-center',\n",
       "  'content': '',\n",
       "  'domain': 'ndtv.com',\n",
       "  'fact': 'HIGH',\n",
       "  'link': 'http://archives.ndtv.com/articles/2014-01.html',\n",
       "  'source_url': 'https://www.ndtv.com/',\n",
       "  'source_url_processed': 'ndtv.com',\n",
       "  'title': ''},\n",
       " 6: {'URL': 'http://mediabiasfactcheck.com/world-news/',\n",
       "  'bias': 'center',\n",
       "  'content': '',\n",
       "  'domain': 'wn.com',\n",
       "  'fact': 'HIGH',\n",
       "  'link': 'http://archive.wn.com/2014/01/01/worldnews/',\n",
       "  'source_url': 'http://wn.com/',\n",
       "  'source_url_processed': 'wn.com',\n",
       "  'title': ''},\n",
       " 7: {'URL': 'http://mediabiasfactcheck.com/rappler/',\n",
       "  'bias': 'left',\n",
       "  'content': '',\n",
       "  'domain': 'rappler.com',\n",
       "  'fact': 'MIXED',\n",
       "  'link': 'https://www.rappler.com/sitemap-2013.xml',\n",
       "  'source_url': 'http://www.rappler.com/',\n",
       "  'source_url_processed': 'rappler.com',\n",
       "  'title': ''}}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_alternative_links('http://fox13now.com/2013/12/30/new-year-new-laws-obamacare-pot-guns-and-drones/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dkj' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-135-77740239b9cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdkj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dkj' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
